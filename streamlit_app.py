import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from io import StringIO
import warnings
warnings.filterwarnings("ignore")

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="ML Studio - An√°lise e Modelagem",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS customizado
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .section-header {
        font-size: 1.5rem;
        color: #2e8b57;
        margin-top: 2rem;
        margin-bottom: 1rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
    }
    .stAlert {
        margin-top: 1rem;
    }
</style>
""", unsafe_allow_html=True)

def show_home_page():
    """P√°gina inicial com informa√ß√µes sobre a aplica√ß√£o"""
    st.markdown("<h2 class=\"section-header\">Bem-vindo ao ML Studio!</h2>", unsafe_allow_html=True)
    
    st.markdown("""
    Esta aplica√ß√£o oferece uma interface completa para an√°lise de dados e machine learning, incluindo:
    
    ### üéØ Funcionalidades Principais:
    - **Upload de Dados**: Carregue seus datasets em formato CSV
    - **An√°lise Explorat√≥ria**: Visualize estat√≠sticas, correla√ß√µes e distribui√ß√µes
    - **Sele√ß√£o de Vari√°veis**: Escolha as features mais relevantes para seu modelo
    - **Modelagem ML**: Treine modelos de classifica√ß√£o, regress√£o ou clustering
    - **Avalia√ß√£o**: Analise m√©tricas de performance dos modelos
    - **Previs√µes**: Fa√ßa previs√µes com novos dados
    
    ### üõ†Ô∏è Tecnologias Utilizadas:
    - **Streamlit**: Interface web interativa
    - **PyCaret**: Framework de machine learning automatizado
    - **Pandas**: Manipula√ß√£o de dados
    - **Plotly/Matplotlib**: Visualiza√ß√µes interativas
    
    ### üöÄ Como Come√ßar:
    1. V√° para "üìä Upload e An√°lise de Dados" para carregar seu dataset
    2. Explore seus dados na se√ß√£o "üîç An√°lise Explorat√≥ria"
    3. Configure seu modelo em "‚öôÔ∏è Configura√ß√£o do Modelo"
    4. Treine e avalie em "üéØ Treinamento e Avalia√ß√£o"
    5. Fa√ßa previs√µes em "üîÆ Previs√µes"
    """)
    
    # Informa√ß√µes sobre o dataset de exemplo
    st.markdown("<h3 class=\"section-header\">üìÅ Dataset de Exemplo</h3>", unsafe_allow_html=True)
    st.info("""
    üí° **Dica**: Se voc√™ n√£o tem um dataset pr√≥prio, pode usar o dataset do Spotify que j√° est√° inclu√≠do no projeto!
    V√° para a se√ß√£o de upload e carregue o arquivo de exemplo.
    """)

def show_data_upload_page():
    """P√°gina para upload e visualiza√ß√£o inicial dos dados"""
    st.markdown("<h2 class=\"section-header\">üìä Upload e An√°lise de Dados</h2>", unsafe_allow_html=True)
    
    # Op√ß√µes de carregamento
    upload_option = st.radio(
        "Como voc√™ gostaria de carregar os dados?",
        ["üìÅ Upload de arquivo CSV", "üéµ Usar dataset do Spotify (exemplo)"]
    )
    
    if upload_option == "üìÅ Upload de arquivo CSV":
        uploaded_file = st.file_uploader(
            "Escolha um arquivo CSV",
            type=["csv"],
            help="Carregue um arquivo CSV com seus dados para an√°lise"
        )
        
        if uploaded_file is not None:
            try:
                # Ler o arquivo
                df = pd.read_csv(uploaded_file)
                st.session_state.df = df
                st.success(f"‚úÖ Arquivo carregado com sucesso! {df.shape[0]} linhas e {df.shape[1]} colunas.")
                
            except Exception as e:
                st.error(f"‚ùå Erro ao carregar o arquivo: {str(e)}")
                return
    
    elif upload_option == "üéµ Usar dataset do Spotify (exemplo)":
        try:
            # Tentar carregar o dataset do Spotify
            spotify_files = [
                "data/SpotifyFeatures.csv",
                "data/spotify_songs.csv",
                "data/tracks.csv",
                "data/dataset.csv"
            ]
            
            loaded = False
            for file_path in spotify_files:
                try:
                    df = pd.read_csv(file_path)
                    st.session_state.df = df
                    st.success(f"‚úÖ Dataset do Spotify carregado! {df.shape[0]} linhas e {df.shape[1]} colunas.")
                    loaded = True
                    break
                except:
                    continue
            
            if not loaded:
                st.warning("‚ö†Ô∏è Dataset do Spotify n√£o encontrado. Por favor, fa√ßa upload de um arquivo CSV.")
                return
                
        except Exception as e:
            st.error(f"‚ùå Erro ao carregar dataset do Spotify: {str(e)}")
            return
    
    # Mostrar informa√ß√µes do dataset se carregado
    if st.session_state.df is not None:
        df = st.session_state.df
        
        # Informa√ß√µes b√°sicas
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.markdown(f"""
            <div class="metric-card">
                <h4>üìä Linhas</h4>
                <h2>{df.shape[0]:,}</h2>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown(f"""
            <div class="metric-card">
                <h4>üìã Colunas</h4>
                <h2>{df.shape[1]:,}</h2>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            st.markdown(f"""
            <div class="metric-card">
                <h4>üî¢ Num√©ricas</h4>
                <h2>{len(df.select_dtypes(include=[np.number]).columns)}</h2>
            </div>
            """, unsafe_allow_html=True)
        
        with col4:
            st.markdown(f"""
            <div class="metric-card">
                <h4>üìù Categ√≥ricas</h4>
                <h2>{len(df.select_dtypes(include=["object"]).columns)}</h2>
            </div>
            """, unsafe_allow_html=True)
        
        # Preview dos dados
        st.markdown("<h3 class=\"section-header\">üëÄ Preview dos Dados</h3>", unsafe_allow_html=True)
        st.dataframe(df.head(10), use_container_width=True)
        
        # Informa√ß√µes sobre tipos de dados
        st.markdown("<h3 class=\"section-header\">üìã Informa√ß√µes das Colunas</h3>", unsafe_allow_html=True)
        
        col_info = pd.DataFrame({
            "Coluna": df.columns,
            "Tipo": df.dtypes,
            "Valores √önicos": [df[col].nunique() for col in df.columns],
            "Valores Nulos": [df[col].isnull().sum() for col in df.columns],
            "% Nulos": [round(df[col].isnull().sum() / len(df) * 100, 2) for col in df.columns]
        })
        
        st.dataframe(col_info, use_container_width=True)
        
        # Bot√£o para pr√≥xima etapa
        if st.button("‚û°Ô∏è Prosseguir para An√°lise Explorat√≥ria", type="primary"):
            st.success("‚úÖ Dados carregados! V√° para a se√ß√£o \'An√°lise Explorat√≥ria\' no menu lateral.")

def show_exploratory_analysis_page():
    """P√°gina para an√°lise explorat√≥ria de dados"""
    st.markdown("<h2 class=\"section-header\">üîç An√°lise Explorat√≥ria de Dados</h2>", unsafe_allow_html=True)
    
    if st.session_state.df is None:
        st.warning("‚ö†Ô∏è Nenhum dataset carregado. Por favor, v√° para a se√ß√£o \'Upload e An√°lise de Dados\' primeiro.")
        return
    
    df = st.session_state.df
    
    # Tabs para diferentes tipos de an√°lise
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üìä Estat√≠sticas Descritivas", 
        "üìà Distribui√ß√µes", 
        "üîó Correla√ß√µes", 
        "üîç Valores Ausentes",
        "üìã An√°lise de Vari√°veis"
    ])
    
    with tab1:
        st.markdown("<h3 class=\"section-header\">üìä Estat√≠sticas Descritivas</h3>", unsafe_allow_html=True)
        
        # Estat√≠sticas para vari√°veis num√©ricas
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            st.markdown("**Vari√°veis Num√©ricas:**")
            st.dataframe(df[numeric_cols].describe(), use_container_width=True)
        
        # Estat√≠sticas para vari√°veis categ√≥ricas
        categorical_cols = df.select_dtypes(include=["object"]).columns
        if len(categorical_cols) > 0:
            st.markdown("**Vari√°veis Categ√≥ricas:**")
            cat_stats = pd.DataFrame({
                "Coluna": categorical_cols,
                "Valores √önicos": [df[col].nunique() for col in categorical_cols],
                "Valor Mais Frequente": [df[col].mode().iloc[0] if len(df[col].mode()) > 0 else "N/A" for col in categorical_cols],
                "Frequ√™ncia do Mais Comum": [df[col].value_counts().iloc[0] if len(df[col].value_counts()) > 0 else 0 for col in categorical_cols]
            })
            st.dataframe(cat_stats, use_container_width=True)
    
    with tab2:
        st.markdown("<h3 class=\"section-header\">üìà Distribui√ß√µes das Vari√°veis</h3>", unsafe_allow_html=True)
        
        # Sele√ß√£o de vari√°vel para an√°lise
        if len(numeric_cols) > 0:
            selected_numeric = st.selectbox("Selecione uma vari√°vel num√©rica:", numeric_cols)
            
            col1, col2 = st.columns(2)
            
            with col1:
                # Histograma
                fig_hist = px.histogram(
                    df, 
                    x=selected_numeric, 
                    title=f"Distribui√ß√£o de {selected_numeric}",
                    nbins=30
                )
                fig_hist.update_layout(height=400)
                st.plotly_chart(fig_hist, use_container_width=True)
            
            with col2:
                # Box plot
                fig_box = px.box(
                    df, 
                    y=selected_numeric, 
                    title=f"Box Plot de {selected_numeric}"
                )
                fig_box.update_layout(height=400)
                st.plotly_chart(fig_box, use_container_width=True)
        
        # An√°lise de vari√°veis categ√≥ricas
        if len(categorical_cols) > 0:
            selected_categorical = st.selectbox("Selecione uma vari√°vel categ√≥rica:", categorical_cols)
            
            # Gr√°fico de barras para vari√°veis categ√≥ricas
            value_counts = df[selected_categorical].value_counts().head(20)
            fig_bar = px.bar(
                x=value_counts.index, 
                y=value_counts.values,
                title=f"Distribui√ß√£o de {selected_categorical} (Top 20)",
                labels={"x": selected_categorical, "y": "Frequ√™ncia"}
            )
            fig_bar.update_layout(height=400)
            st.plotly_chart(fig_bar, use_container_width=True)
    
    with tab3:
        st.markdown("<h3 class=\"section-header\">üîó An√°lise de Correla√ß√µes</h3>", unsafe_allow_html=True)
        
        if len(numeric_cols) > 1:
            # Matriz de correla√ß√£o
            corr_matrix = df[numeric_cols].corr()
            
            # Heatmap de correla√ß√£o
            fig_corr = px.imshow(
                corr_matrix,
                title="Matriz de Correla√ß√£o",
                color_continuous_scale="RdBu",
                aspect="auto"
            )
            fig_corr.update_layout(height=600)
            st.plotly_chart(fig_corr, use_container_width=True)
            
            # Correla√ß√µes mais altas
            st.markdown("**Correla√ß√µes mais fortes (> 0.5 ou < -0.5):**")
            
            # Encontrar correla√ß√µes altas
            high_corr = []
            for i in range(len(corr_matrix.columns)):
                for j in range(i+1, len(corr_matrix.columns)):
                    corr_val = corr_matrix.iloc[i, j]
                    if abs(corr_val) > 0.5:
                        high_corr.append({
                            "Vari√°vel 1": corr_matrix.columns[i],
                            "Vari√°vel 2": corr_matrix.columns[j],
                            "Correla√ß√£o": round(corr_val, 3)
                        })
            
            if high_corr:
                high_corr_df = pd.DataFrame(high_corr)
                high_corr_df = high_corr_df.sort_values("Correla√ß√£o", key=abs, ascending=False)
                st.dataframe(high_corr_df, use_container_width=True)
            else:
                st.info("Nenhuma correla√ß√£o forte encontrada (> 0.5 ou < -0.5)")
        else:
            st.info("Necess√°rio pelo menos 2 vari√°veis num√©ricas para an√°lise de correla√ß√£o.")
    
    with tab4:
        st.markdown("<h3 class=\"section-header\">üîç An√°lise de Valores Ausentes</h3>", unsafe_allow_html=True)
        
        # Contagem de valores ausentes
        missing_data = df.isnull().sum()
        missing_percent = (missing_data / len(df)) * 100
        
        missing_df = pd.DataFrame({
            "Coluna": missing_data.index,
            "Valores Ausentes": missing_data.values,
            "Percentual (%)": missing_percent.values
        })
        missing_df = missing_df[missing_df["Valores Ausentes"] > 0].sort_values("Valores Ausentes", ascending=False)
        
        if len(missing_df) > 0:
            st.dataframe(missing_df, use_container_width=True)
            
            # Gr√°fico de valores ausentes
            fig_missing = px.bar(
                missing_df, 
                x="Coluna", 
                y="Percentual (%)",
                title="Percentual de Valores Ausentes por Coluna"
            )
            fig_missing.update_layout(height=400)
            st.plotly_chart(fig_missing, use_container_width=True)
        else:
            st.success("‚úÖ Nenhum valor ausente encontrado no dataset!")
    
    with tab5:
        st.markdown("<h3 class=\"section-header\">üìã An√°lise Detalhada de Vari√°veis</h3>", unsafe_allow_html=True)
        
        # Sele√ß√£o de vari√°vel para an√°lise detalhada
        all_columns = df.columns.tolist()
        selected_column = st.selectbox("Selecione uma vari√°vel para an√°lise detalhada:", all_columns)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown(f"**Informa√ß√µes sobre \'{selected_column}\':**")
            
            info_data = {
                "Tipo de Dados": str(df[selected_column].dtype),
                "Valores √önicos": df[selected_column].nunique(),
                "Valores Nulos": df[selected_column].isnull().sum(),
                "Percentual Nulos": f"{(df[selected_column].isnull().sum() / len(df)) * 100:.2f}%"
            }
            
            if df[selected_column].dtype in ["int64", "float64"]:
                info_data.update({
                    "M√≠nimo": df[selected_column].min(),
                    "M√°ximo": df[selected_column].max(),
                    "M√©dia": round(df[selected_column].mean(), 3),
                    "Mediana": df[selected_column].median(),
                    "Desvio Padr√£o": round(df[selected_column].std(), 3)
                })
            
            for key, value in info_data.items():
                st.metric(key, value)
        
        with col2:
            st.markdown(f"**Valores mais frequentes em \'{selected_column}\':**")
            
            value_counts = df[selected_column].value_counts().head(10)
            value_counts_df = pd.DataFrame({
                "Valor": value_counts.index,
                "Frequ√™ncia": value_counts.values,
                "Percentual (%)": round((value_counts.values / len(df)) * 100, 2)
            })
            
            st.dataframe(value_counts_df, use_container_width=True)

def show_model_configuration_page():
    """P√°gina para configura√ß√£o do modelo de ML"""
    st.markdown("<h2 class=\"section-header\">‚öôÔ∏è Configura√ß√£o do Modelo</h2>", unsafe_allow_html=True)
    
    if st.session_state.df is None:
        st.warning("‚ö†Ô∏è Nenhum dataset carregado. Por favor, v√° para a se√ß√£o \'Upload e An√°lise de Dados\' primeiro.")
        return
    
    df = st.session_state.df
    
    # Sele√ß√£o do tipo de tarefa
    st.markdown("<h3 class=\"section-header\">üéØ Tipo de Tarefa de Machine Learning</h3>", unsafe_allow_html=True)
    
    task_type = st.selectbox(
        "Selecione o tipo de tarefa:",
        ["Classifica√ß√£o", "Regress√£o", "Clustering"],
        help="Escolha o tipo de problema que voc√™ quer resolver"
    )
    
    # Mapear para valores do PyCaret
    task_mapping = {
        "Classifica√ß√£o": "classification",
        "Regress√£o": "regression", 
        "Clustering": "clustering"
    }
    
    st.session_state.task_type = task_mapping[task_type]
    
    # Configura√ß√£o espec√≠fica por tipo de tarefa
    if task_type in ["Classifica√ß√£o", "Regress√£o"]:
        st.markdown("<h3 class=\"section-header\">üéØ Sele√ß√£o da Vari√°vel Alvo</h3>", unsafe_allow_html=True)
        
        # Filtrar colunas apropriadas para cada tipo
        if task_type == "Classifica√ß√£o":
            # Para classifica√ß√£o, mostrar colunas categ√≥ricas e num√©ricas com poucos valores √∫nicos
            suitable_cols = []
            for col in df.columns:
                if df[col].dtype == "object" or df[col].nunique() <= 20:
                    suitable_cols.append(col)
        else:  # Regress√£o
            # Para regress√£o, mostrar apenas colunas num√©ricas
            suitable_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        if len(suitable_cols) > 0:
            target_column = st.selectbox(
                "Selecione a vari√°vel alvo (target):",
                suitable_cols,
                help=f"Para {task_type.lower()}, selecione a vari√°vel que voc√™ quer prever"
            )
            
            st.session_state.target_column = target_column
            
            # Mostrar informa√ß√µes sobre a vari√°vel alvo
            st.markdown(f"**Informa√ß√µes sobre \'{target_column}\':**")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("Valores √önicos", df[target_column].nunique())
            
            with col2:
                st.metric("Valores Nulos", df[target_column].isnull().sum())
            
            with col3:
                if df[target_column].dtype in ["int64", "float64"]:
                    st.metric("M√©dia", round(df[target_column].mean(), 3))
                else:
                    most_common = df[target_column].mode().iloc[0] if len(df[target_column].mode()) > 0 else "N/A"
                    st.metric("Mais Frequente", most_common)
            
            # Distribui√ß√£o da vari√°vel alvo
            if task_type == "Classifica√ß√£o":
                st.markdown("**Distribui√ß√£o da Vari√°vel Alvo:**")
                target_counts = df[target_column].value_counts()
                fig_target = px.bar(
                    x=target_counts.index,
                    y=target_counts.values,
                    title=f"Distribui√ß√£o de {target_column}",
                    labels={"x": target_column, "y": "Frequ√™ncia"}
                )
                st.plotly_chart(fig_target, use_container_width=True)
            else:  # Regress√£o
                st.markdown("**Distribui√ß√£o da Vari√°vel Alvo:**")
                fig_target = px.histogram(
                    df,
                    x=target_column,
                    title=f"Distribui√ß√£o de {target_column}",
                    nbins=30
                )
                st.plotly_chart(fig_target, use_container_width=True)
        else:
            st.error(f"‚ùå Nenhuma coluna adequada encontrada para {task_type.lower()}.")
            return
    
    else:  # Clustering
        st.info("üí° Para clustering, todas as vari√°veis num√©ricas ser√£o utilizadas automaticamente.")
        st.session_state.target_column = None
    
    # Sele√ß√£o de features
    st.markdown("<h3 class=\"section-header\">üîß Sele√ß√£o de Vari√°veis (Features)</h3>", unsafe_allow_html=True)
    
    # Obter todas as colunas exceto a target (se houver)
    available_features = df.columns.tolist()
    if st.session_state.target_column:
        available_features = [col for col in available_features if col != st.session_state.target_column]
    
    # Separar por tipo
    numeric_features = df[available_features].select_dtypes(include=[np.number]).columns.tolist()
    categorical_features = df[available_features].select_dtypes(include=["object"]).columns.tolist()
    
    # Interface para sele√ß√£o de features
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**Vari√°veis Num√©ricas:**")
        selected_numeric = st.multiselect(
            "Selecione as vari√°veis num√©ricas:",
            numeric_features,
            default=numeric_features[:10] if len(numeric_features) > 10 else numeric_features,
            help="Selecione as vari√°veis num√©ricas que ser√£o usadas no modelo"
        )
    
    with col2:
        st.markdown("**Vari√°veis Categ√≥ricas:**")
        selected_categorical = st.multiselect(
            "Selecione as vari√°veis categ√≥ricas:",
            categorical_features,
            default=categorical_features[:5] if len(categorical_features) > 5 else categorical_features,
            help="Selecione as vari√°veis categ√≥ricas que ser√£o usadas no modelo"
        )
    
    # Combinar features selecionadas
    selected_features = selected_numeric + selected_categorical
    st.session_state.selected_features = selected_features
    
    # Mostrar resumo da sele√ß√£o
    if selected_features:
        st.markdown("<h3 class=\"section-header\">üìã Resumo da Configura√ß√£o</h3>", unsafe_allow_html=True)
        
        config_summary = {
            "Tipo de Tarefa": task_type,
            "Vari√°vel Alvo": st.session_state.target_column if st.session_state.target_column else "N/A (Clustering)",
            "Total de Features": len(selected_features),
            "Features Num√©ricas": len(selected_numeric),
            "Features Categ√≥ricas": len(categorical_features)
        }
        
        for key, value in config_summary.items():
            st.metric(key, value)
        
        # Mostrar features selecionadas
        st.markdown("**Features Selecionadas:**")
        features_df = pd.DataFrame({
            "Feature": selected_features,
            "Tipo": [df[col].dtype for col in selected_features],
            "Valores √önicos": [df[col].nunique() for col in selected_features],
            "Valores Nulos": [df[col].isnull().sum() for col in selected_features]
        })
        st.dataframe(features_df, use_container_width=True)
        
        # Bot√£o para prosseguir
        if st.button("‚û°Ô∏è Prosseguir para Treinamento", type="primary"):
            st.success("‚úÖ Configura√ß√£o salva! V√° para a se√ß√£o \'Treinamento e Avalia√ß√£o\' no menu lateral.")
    
    else:
        st.warning("‚ö†Ô∏è Selecione pelo menos uma feature para continuar.")

def show_training_page():
    """P√°gina para treinamento e avalia√ß√£o do modelo"""
    st.markdown("<h2 class=\"section-header\">üéØ Treinamento e Avalia√ß√£o do Modelo</h2>", unsafe_allow_html=True)
    
    if st.session_state.df is None:
        st.warning("‚ö†Ô∏è Nenhum dataset carregado. Por favor, configure o modelo primeiro.")
        return
    
    if st.session_state.task_type is None or st.session_state.selected_features is None:
        st.warning("‚ö†Ô∏è Configure o modelo primeiro na se√ß√£o \'Configura√ß√£o do Modelo\'.")
        return
    
    df = st.session_state.df
    
    # Preparar dados para treinamento
    if st.session_state.target_column:
        # Para classifica√ß√£o e regress√£o
        features_data = df[st.session_state.selected_features + [st.session_state.target_column]].copy()
    else:
        # Para clustering
        features_data = df[st.session_state.selected_features].copy()
    
    # Remover linhas com valores nulos
    initial_rows = len(features_data)
    features_data = features_data.dropna()
    final_rows = len(features_data)
    
    if initial_rows != final_rows:
        st.info(f"‚ÑπÔ∏è Removidas {initial_rows - final_rows} linhas com valores nulos. Dataset final: {final_rows} linhas.")
    
    # Mostrar configura√ß√£o atual
    st.markdown("<h3 class=\"section-header\">üìã Configura√ß√£o Atual</h3>", unsafe_allow_html=True)
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Tipo de Tarefa", st.session_state.task_type.title())
    
    with col2:
        st.metric("Linhas para Treino", final_rows)
    
    with col3:
        st.metric("Features", len(st.session_state.selected_features))
    
    with col4:
        target_display = st.session_state.target_column if st.session_state.target_column else "N/A"
        st.metric("Vari√°vel Alvo", target_display)
    
    # Bot√£o para iniciar treinamento
    if st.button("üöÄ Iniciar Treinamento", type="primary"):
        
        with st.spinner("üîÑ Treinando modelos... Isso pode levar alguns minutos."):
            try:
                # Importar PyCaret baseado no tipo de tarefa
                if st.session_state.task_type == "classification":
                    from pycaret.classification import setup, compare_models, finalize_model, evaluate_model, get_config
                elif st.session_state.task_type == "regression":
                    from pycaret.regression import setup, compare_models, finalize_model, evaluate_model, get_config
                else:  # clustering
                    from pycaret.clustering import setup, create_model, assign_model, get_config
                
                # Setup do PyCaret
                if st.session_state.task_type in ["classification", "regression"]:
                    ml_setup = setup(
                        data=features_data,
                        target=st.session_state.target_column,
                        session_id=123,
                        train_size=0.8,
                        silent=True,
                        html=False,
                        verbose=False
                    )
                    
                    # Comparar modelos
                    best_models = compare_models(
                        include=["lr", "rf", "et", "gbr" if st.session_state.task_type == "regression" else "gbc", "xgboost"],
                        sort="RMSE" if st.session_state.task_type == "regression" else "Accuracy",
                        n_select=3,
                        verbose=False
                    )
                    
                    # Finalizar o melhor modelo
                    if isinstance(best_models, list):
                        best_model = finalize_model(best_models[0])
                    else:
                        best_model = finalize_model(best_models)
                    
                    st.session_state.model = best_model
                    
                else:  # clustering
                    ml_setup = setup(
                        data=features_data,
                        session_id=123,
                        silent=True,
                        html=False,
                        verbose=False
                    )
                    
                    # Criar modelo de clustering
                    kmeans_model = create_model("kmeans", num_clusters=3)
                    
                    # Atribuir clusters
                    clustered_data = assign_model(kmeans_model)
                    
                    st.session_state.model = kmeans_model
                    st.session_state.clustered_data = clustered_data
                
                st.success("‚úÖ Treinamento conclu√≠do com sucesso!")
                
                # Mostrar resultados
                st.markdown("<h3 class=\"section-header\">üìä Resultados do Treinamento</h3>", unsafe_allow_html=True)
                
                if st.session_state.task_type in ["classification", "regression"]:
                    # M√©tricas do modelo
                    st.markdown("**Melhor Modelo Treinado:**")
                    st.write(f"Algoritmo: {type(best_model).__name__}")
                    
                    # Avalia√ß√£o do modelo
                    try:
                        # Obter m√©tricas do setup
                        X_test = get_config("X_test")
                        y_test = get_config("y_test")
                        
                        if st.session_state.task_type == "classification":
                            from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
                            
                            y_pred = best_model.predict(X_test)
                            accuracy = accuracy_score(y_test, y_pred)
                            
                            st.metric("Acur√°cia no Teste", f"{accuracy:.3f}")
                            
                            # Matriz de confus√£o
                            cm = confusion_matrix(y_test, y_pred)
                            fig_cm = px.imshow(
                                cm,
                                title="Matriz de Confus√£o",
                                labels=dict(x="Predito", y="Real"),
                                color_continuous_scale="Blues"
                            )
                            st.plotly_chart(fig_cm, use_container_width=True)
                            
                        else:  # regression
                            from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
                            
                            y_pred = best_model.predict(X_test)
                            mse = mean_squared_error(y_test, y_pred)
                            rmse = np.sqrt(mse)
                            r2 = r2_score(y_test, y_pred)
                            mae = mean_absolute_error(y_test, y_pred)
                            
                            col1, col2, col3, col4 = st.columns(4)
                            
                            with col1:
                                st.metric("R¬≤ Score", f"{r2:.3f}")
                            with col2:
                                st.metric("RMSE", f"{rmse:.3f}")
                            with col3:
                                st.metric("MAE", f"{mae:.3f}")
                            with col4:
                                st.metric("MSE", f"{mse:.3f}")
                            
                            # Gr√°fico de predi√ß√µes vs real
                            fig_pred = px.scatter(
                                x=y_test,
                                y=y_pred,
                                title="Predi√ß√µes vs Valores Reais",
                                labels={"x": "Valores Reais", "y": "Predi√ß√µes"}
                            )
                            fig_pred.add_shape(
                                type="line",
                                x0=y_test.min(),
                                y0=y_test.min(),
                                x1=y_test.max(),
                                y1=y_test.max(),
                                line=dict(color="red", dash="dash")
                            )
                            st.plotly_chart(fig_pred, use_container_width=True)
                    
                    except Exception as e:
                        st.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel gerar todas as m√©tricas: {str(e)}")
                
                else:  # clustering
                    st.markdown("**Modelo de Clustering Criado:**")
                    st.write(f"Algoritmo: K-Means")
                    st.write(f"N√∫mero de Clusters: 3")
                    
                    # Mostrar distribui√ß√£o dos clusters
                    cluster_counts = clustered_data["Cluster"].value_counts().sort_index()
                    
                    fig_clusters = px.bar(
                        x=cluster_counts.index,
                        y=cluster_counts.values,
                        title="Distribui√ß√£o dos Clusters",
                        labels={"x": "Cluster", "y": "N√∫mero de Pontos"}
                    )
                    st.plotly_chart(fig_clusters, use_container_width=True)
                    
                    # Visualiza√ß√£o 2D dos clusters (usando as duas primeiras features num√©ricas)
                    numeric_features = features_data.select_dtypes(include=[np.number]).columns[:2]
                    if len(numeric_features) >= 2:
                        fig_scatter = px.scatter(
                            clustered_data,
                            x=numeric_features[0],
                            y=numeric_features[1],
                            color="Cluster",
                            title=f"Clusters - {numeric_features[0]} vs {numeric_features[1]}"
                        )
                        st.plotly_chart(fig_scatter, use_container_width=True)
                
                # Bot√£o para pr√≥xima etapa
                if st.button("‚û°Ô∏è Fazer Previs√µes", type="secondary"):
                    st.success("‚úÖ Modelo treinado! V√° para a se√ß√£o \'Previs√µes\' no menu lateral.")
                
            except Exception as e:
                st.error(f"‚ùå Erro durante o treinamento: {str(e)}")
                st.error("Verifique se os dados est√£o no formato correto e tente novamente.")
    
    # Mostrar informa√ß√µes sobre o modelo atual se j√° treinado
    elif st.session_state.model is not None:
        st.success("‚úÖ Modelo j√° treinado e pronto para uso!")
        st.info("üí° Voc√™ pode retreinar o modelo clicando no bot√£o acima ou ir para a se√ß√£o de previs√µes.")

def show_prediction_page():
    """P√°gina para fazer previs√µes com novos dados"""
    st.markdown("<h2 class=\"section-header\">üîÆ Previs√µes com Novos Dados</h2>", unsafe_allow_html=True)
    
    if st.session_state.model is None:
        st.warning("‚ö†Ô∏è Nenhum modelo treinado. Por favor, treine um modelo primeiro na se√ß√£o \'Treinamento e Avalia√ß√£o\'.")
        return
    
    if st.session_state.selected_features is None:
        st.warning("‚ö†Ô∏è Configure o modelo primeiro na se√ß√£o \'Configura√ß√£o do Modelo\'.")
        return
    
    # Informa√ß√µes sobre o modelo atual
    st.markdown("<h3 class=\"section-header\">üìã Modelo Atual</h3>", unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Tipo de Tarefa", st.session_state.task_type.title())
    
    with col2:
        st.metric("Algoritmo", type(st.session_state.model).__name__)
    
    with col3:
        st.metric("Features Necess√°rias", len(st.session_state.selected_features))
    
    # Op√ß√µes para entrada de dados
    st.markdown("<h3 class=\"section-header\">üìù Entrada de Dados para Previs√£o</h3>", unsafe_allow_html=True)
    
    input_method = st.radio(
        "Como voc√™ gostaria de inserir os dados?",
        ["üìù Entrada Manual", "üìÅ Upload de Arquivo CSV"]
    )
    
    if input_method == "üìù Entrada Manual":
        st.markdown("**Insira os valores para cada feature:**")
        
        # Criar formul√°rio para entrada manual
        with st.form("prediction_form"):
            input_data = {}
            
            # Organizar em colunas para melhor layout
            num_cols = 3
            cols = st.columns(num_cols)
            
            for i, feature in enumerate(st.session_state.selected_features):
                col_idx = i % num_cols
                
                with cols[col_idx]:
                    # Verificar tipo da feature no dataset original
                    if st.session_state.df[feature].dtype in ["int64", "float64"]:
                        # Feature num√©rica
                        min_val = float(st.session_state.df[feature].min())
                        max_val = float(st.session_state.df[feature].max())
                        mean_val = float(st.session_state.df[feature].mean())
                        
                        input_data[feature] = st.number_input(
                            f"{feature}",
                            min_value=min_val,
                            max_value=max_val,
                            value=mean_val,
                            help=f"Valor entre {min_val:.2f} e {max_val:.2f}"
                        )
                    else:
                        # Feature categ√≥rica
                        unique_values = st.session_state.df[feature].unique()
                        unique_values = [val for val in unique_values if pd.notna(val)]
                        
                        input_data[feature] = st.selectbox(
                            f"{feature}",
                            unique_values,
                            help=f"Selecione um valor para {feature}"
                        )
            
            # Bot√£o para fazer previs√£o
            submitted = st.form_submit_button("üîÆ Fazer Previs√£o", type="primary")
            
            if submitted:
                try:
                    # Criar DataFrame com os dados de entrada
                    input_df = pd.DataFrame([input_data])
                    
                    # Fazer previs√£o
                    if st.session_state.task_type in ["classification", "regression"]:
                        prediction = st.session_state.model.predict(input_df)[0]
                        
                        # Mostrar resultado
                        st.markdown("<h3 class=\"section-header\">üéØ Resultado da Previs√£o</h3>", unsafe_allow_html=True)
                        
                        if st.session_state.task_type == "classification":
                            st.success(f"**Classe Predita:** {prediction}")
                            
                            # Tentar obter probabilidades se dispon√≠vel
                            try:
                                probabilities = st.session_state.model.predict_proba(input_df)[0]
                                classes = st.session_state.model.classes_
                                
                                prob_df = pd.DataFrame({
                                    "Classe": classes,
                                    "Probabilidade": probabilities
                                }).sort_values("Probabilidade", ascending=False)
                                
                                st.markdown("**Probabilidades por Classe:**")
                                
                                # Gr√°fico de barras das probabilidades
                                fig_prob = px.bar(
                                    prob_df,
                                    x="Classe",
                                    y="Probabilidade",
                                    title="Probabilidades de Classifica√ß√£o"
                                )
                                st.plotly_chart(fig_prob, use_container_width=True)
                                
                                # Tabela das probabilidades
                                prob_df["Probabilidade"] = prob_df["Probabilidade"].apply(lambda x: f"{x:.3f}")
                                st.dataframe(prob_df, use_container_width=True)
                                
                            except:
                                st.info("‚ÑπÔ∏è Probabilidades n√£o dispon√≠veis para este modelo.")
                        
                        else:  # regression
                            st.success(f"**Valor Predito:** {prediction:.3f}")
                            
                            # Mostrar contexto da previs√£o
                            target_col = st.session_state.target_column
                            target_min = st.session_state.df[target_col].min()
                            target_max = st.session_state.df[target_col].max()
                            target_mean = st.session_state.df[target_col].mean()
                            
                            col1, col2, col3, col4 = st.columns(4)
                            
                            with col1:
                                st.metric("Predi√ß√£o", f"{prediction:.3f}")
                            with col2:
                                st.metric("M√≠nimo no Dataset", f"{target_min:.3f}")
                            with col3:
                                st.metric("M√°ximo no Dataset", f"{target_max:.3f}")
                            with col4:
                                st.metric("M√©dia no Dataset", f"{target_mean:.3f}")
                    
                    else:  # clustering
                        # Para clustering, atribuir cluster
                        from pycaret.clustering import assign_model
                        
                        clustered_input = assign_model(st.session_state.model, data=input_df)
                        cluster = clustered_input["Cluster"].iloc[0]
                        
                        st.success(f"**Cluster Atribu√≠do:** {cluster}")
                        
                        # Mostrar informa√ß√µes sobre o cluster
                        if hasattr(st.session_state, "clustered_data"):
                            cluster_data = st.session_state.clustered_data
                            cluster_info = cluster_data[cluster_data["Cluster"] == cluster]
                            
                            st.markdown(f"**Informa√ß√µes sobre o Cluster {cluster}:**")
                            
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                st.metric("Pontos no Cluster", len(cluster_info))
                            
                            with col2:
                                total_points = len(cluster_data)
                                percentage = (len(cluster_info) / total_points) * 100
                                st.metric("% do Total", f"{percentage:.1f}%")
                    
                    # Mostrar dados de entrada
                    st.markdown("<h3 class=\"section-header\">üìä Dados de Entrada</h3>", unsafe_allow_html=True)
                    st.dataframe(input_df, use_container_width=True)
                    
                except Exception as e:
                    st.error(f"‚ùå Erro ao fazer previs√£o: {str(e)}")
    
    else:  # Upload de arquivo CSV
        st.markdown("**Fa√ßa upload de um arquivo CSV com novos dados:**")
        
        uploaded_file = st.file_uploader(
            "Escolha um arquivo CSV",
            type=["csv"],
            help="O arquivo deve conter as mesmas colunas usadas no treinamento"
        )
        
        if uploaded_file is not None:
            try:
                # Ler arquivo
                new_data = pd.read_csv(uploaded_file)
                
                st.markdown("**Preview dos dados carregados:**")
                st.dataframe(new_data.head(), use_container_width=True)
                
                # Verificar se as colunas necess√°rias est√£o presentes
                missing_features = [feat for feat in st.session_state.selected_features if feat not in new_data.columns]
                
                if missing_features:
                    st.error(f"‚ùå Colunas ausentes no arquivo: {missing_features}")
                    st.info("üí° O arquivo deve conter todas as features usadas no treinamento.")
                else:
                    # Selecionar apenas as features necess√°rias
                    prediction_data = new_data[st.session_state.selected_features].copy()
                    
                    # Verificar valores nulos
                    null_counts = prediction_data.isnull().sum()
                    if null_counts.sum() > 0:
                        st.warning("‚ö†Ô∏è Dados com valores nulos encontrados. Eles ser√£o removidos.")
                        prediction_data = prediction_data.dropna()
                    
                    if len(prediction_data) > 0:
                        if st.button("üîÆ Fazer Previs√µes em Lote", type="primary"):
                            try:
                                with st.spinner("üîÑ Fazendo previs√µes..."):
                                    
                                    if st.session_state.task_type in ["classification", "regression"]:
                                        predictions = st.session_state.model.predict(prediction_data)
                                        
                                        # Adicionar previs√µes ao DataFrame
                                        result_df = prediction_data.copy()
                                        
                                        if st.session_state.task_type == "classification":
                                            result_df["Classe_Predita"] = predictions
                                            
                                            # Tentar obter probabilidades
                                            try:
                                                probabilities = st.session_state.model.predict_proba(prediction_data)
                                                classes = st.session_state.model.classes_
                                                
                                                for i, class_name in enumerate(classes):
                                                    result_df[f"Prob_{class_name}"] = probabilities[:, i]
                                            except:
                                                pass
                                        
                                        else:  # regression
                                            result_df["Valor_Predito"] = predictions
                                    
                                    else:  # clustering
                                        from pycaret.clustering import assign_model
                                        
                                        clustered_result = assign_model(st.session_state.model, data=prediction_data)
                                        result_df = clustered_result
                                    
                                    # Mostrar resultados
                                    st.markdown("<h3 class=\"section-header\">üéØ Resultados das Previs√µes</h3>", unsafe_allow_html=True)
                                    
                                    st.dataframe(result_df, use_container_width=True)
                                    
                                    # Estat√≠sticas das previs√µes
                                    if st.session_state.task_type == "classification":
                                        pred_counts = result_df["Classe_Predita"].value_counts()
                                        
                                        fig_pred_dist = px.bar(
                                            x=pred_counts.index,
                                            y=pred_counts.values,
                                            title="Distribui√ß√£o das Previs√µes",
                                            labels={"x": "Classe Predita", "y": "Frequ√™ncia"}
                                        )
                                        st.plotly_chart(fig_pred_dist, use_container_width=True)
                                    
                                    elif st.session_state.task_type == "regression":
                                        fig_pred_hist = px.histogram(
                                            result_df,
                                            x="Valor_Predito",
                                            title="Distribui√ß√£o dos Valores Preditos",
                                            nbins=30
                                        )
                                        st.plotly_chart(fig_pred_hist, use_container_width=True)
                                    
                                    else:  # clustering
                                        cluster_counts = result_df["Cluster"].value_counts().sort_index()
                                        
                                        fig_cluster_dist = px.bar(
                                            x=cluster_counts.index,
                                            y=cluster_counts.values,
                                            title="Distribui√ß√£o dos Clusters",
                                            labels={"x": "Cluster", "y": "Frequ√™ncia"}
                                        )
                                        st.plotly_chart(fig_cluster_dist, use_container_width=True)
                                    
                                    # Op√ß√£o para download dos resultados
                                    csv_result = result_df.to_csv(index=False)
                                    st.download_button(
                                        label="üì• Download dos Resultados (CSV)",
                                        data=csv_result,
                                        file_name="predicoes_resultado.csv",
                                        mime="text/csv"
                                    )
                                    
                                    st.success(f"‚úÖ Previs√µes conclu√≠das para {len(result_df)} registros!")
                            
                            except Exception as e:
                                st.error(f"‚ùå Erro ao fazer previs√µes: {str(e)}")
                    else:
                        st.error("‚ùå Nenhum dado v√°lido encontrado ap√≥s remo√ß√£o de valores nulos.")
            
            except Exception as e:
                st.error(f"‚ùå Erro ao carregar arquivo: {str(e)}")
    
    # Informa√ß√µes sobre as features necess√°rias
    st.markdown("<h3 class=\"section-header\">üìã Features Necess√°rias</h3>", unsafe_allow_html=True)
    st.info("üí° Para fazer previs√µes, voc√™ precisa fornecer valores para as seguintes features:")
    
    features_info = []
    for feature in st.session_state.selected_features:
        feature_type = "Num√©rica" if st.session_state.df[feature].dtype in ["int64", "float64"] else "Categ√≥rica"
        
        if feature_type == "Num√©rica":
            min_val = st.session_state.df[feature].min()
            max_val = st.session_state.df[feature].max()
            info = f"Valor entre {min_val:.2f} e {max_val:.2f}"
        else:
            unique_vals = st.session_state.df[feature].nunique()
            info = f"{unique_vals} valores √∫nicos"
        
        features_info.append({
            "Feature": feature,
            "Tipo": feature_type,
            "Informa√ß√£o": info
        })
    
    features_df = pd.DataFrame(features_info)
    st.dataframe(features_df, use_container_width=True)

def main():
    # T√≠tulo principal
    st.markdown("<h1 class=\"main-header\">ü§ñ ML Studio - An√°lise e Modelagem</h1>", unsafe_allow_html=True)
    
    # Sidebar para navega√ß√£o
    st.sidebar.title("üìã Menu de Navega√ß√£o")
    
    # Op√ß√µes do menu
    menu_options = [
        "üè† In√≠cio",
        "üìä Upload e An√°lise de Dados",
        "üîç An√°lise Explorat√≥ria",
        "‚öôÔ∏è Configura√ß√£o do Modelo",
        "üéØ Treinamento e Avalia√ß√£o",
        "üîÆ Previs√µes"
    ]
    
    selected_option = st.sidebar.selectbox("Selecione uma op√ß√£o:", menu_options)
    
    # Inicializar session state
    if "df" not in st.session_state:
        st.session_state.df = None
    if "model" not in st.session_state:
        st.session_state.model = None
    if "target_column" not in st.session_state:
        st.session_state.target_column = None
    if "task_type" not in st.session_state:
        st.session_state.task_type = None
    if "selected_features" not in st.session_state:
        st.session_state.selected_features = None
    
    # Roteamento baseado na sele√ß√£o do menu
    if selected_option == "üè† In√≠cio":
        show_home_page()
    elif selected_option == "üìä Upload e An√°lise de Dados":
        show_data_upload_page()
    elif selected_option == "üîç An√°lise Explorat√≥ria":
        show_exploratory_analysis_page()
    elif selected_option == "‚öôÔ∏è Configura√ß√£o do Modelo":
        show_model_configuration_page()
    elif selected_option == "üéØ Treinamento e Avalia√ß√£o":
        show_training_page()
    elif selected_option == "üîÆ Previs√µes":
        show_prediction_page()

if __name__ == "__main__":
    main()
